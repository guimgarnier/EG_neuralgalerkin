{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'New_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunc\u001b[39;00m \u001b[39mimport\u001b[39;00m jacfwd, vmap, grad,jacrev\n\u001b[1;32m     13\u001b[0m \u001b[39m#from lib.model import Model\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmatrixM\u001b[39;00m \u001b[39mimport\u001b[39;00m MatrixM\n\u001b[1;32m     17\u001b[0m \u001b[39m\"\"\" def f(x, y):\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m  return x + y ** 2\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39mx, y = torch.randn(5), torch.randn(5)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mjacobian\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39m \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Third Cycle/Conférences/CEMRACS 2023/inverse-neural-galerkin/src/lib/matrixM.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mNew_model\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n\u001b[1;32m      3\u001b[0m \u001b[39m#from PDEmerge import gradNN\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mMatrixM\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'New_model'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "sys.path.append(module_path)\n",
    "\n",
    "import torch\n",
    "import torch as tc\n",
    "from torch.func import jacfwd, vmap, grad,jacrev\n",
    "\n",
    "#from lib.model import Model\n",
    "from lib.matrixM import MatrixM\n",
    "\n",
    "\n",
    "\"\"\" def f(x, y):\n",
    "  return x + y ** 2\n",
    "x, y = torch.randn(5), torch.randn(5)\n",
    "jacobian = jacfwd(lambda x,y: x+y**2, argnums=1)(x, y)\n",
    "expected = torch.diag(2 * y)\n",
    "assert torch.allclose(jacobian, expected)\n",
    "jacobian\n",
    " \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model():\n",
    "    \n",
    "    def __init__(self, d, m, theta=None, kind='gaussian'):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.m = m       # model parameter \n",
    "        self.d = d       # dimension of b (same as x)\n",
    "        \n",
    "        # size of theta according to the the model\n",
    "        if kind == 'gaussian':\n",
    "            self.s = 2*m+d*m \n",
    "        elif kind== 'nn':\n",
    "            self.L = 0.5\n",
    "            self.l = 3\n",
    "            self.s = m + m*d * self.l + d * self.l \n",
    "        else:\n",
    "            self.s = 2*m+d*m\n",
    "            warnings.warn(\"The type of network has not The theta parameter has not been initialized\") \n",
    "        \n",
    "        # Dictionary of models \n",
    "        methods = {\n",
    "            'gaussian'        : self.gaussian_x,   # Eq. (16)\n",
    "        }\n",
    "\n",
    "        # Warning : une initialisation à ones fait échouer la minimisation pour theta0 !\n",
    "        self.theta = tc.rand(self.s) if theta is None else theta\n",
    "        #self.theta = tc.nn.Parameter(tc.rand(self.s) if theta is None else theta)\n",
    "        #self.theta = tc.nn.Parameter(2.0*tc.ones(self.s) if theta is None else theta) \n",
    "\n",
    "        # batched derivatives , input are (d,)\n",
    "        self.eval_x    = methods[kind]\n",
    "        self.forward   = vmap(self.eval_x)\n",
    "        self.dx        = vmap(grad(self.eval_x),             in_dims=(0,) )\n",
    "        self.dxx       = vmap(grad(grad(self.eval_x)),       in_dims=(0,) )\n",
    "        self.dxxx      = vmap(grad(grad(grad(self.eval_x))), in_dims=(0,) )\n",
    "\n",
    "        # work in progress\n",
    "        # self.dtheta = vmap(lambda x : autograd(self.eval_x(x), self.theta)[0])\n",
    "\n",
    "        \n",
    "    def splitter_gaussian(self):\n",
    "        c = self.theta[:self.m]\n",
    "        b = self.theta[self.m: self.m+self.m*self.d ].reshape(self.m,self.d)\n",
    "        w = self.theta[self.m+self.m*self.d:]\n",
    "        return (c,b,w)\n",
    "    \n",
    "    def splitter_nn(self):\n",
    "        c = self.theta[:self.m]\n",
    "        b=self.theta[self.m:self.m+self.d*self.l].reshape(self.l,self.d)\n",
    "        w=self.theta[self.m+self.d*self.l:].reshape(self.l,self.m,self.d)\n",
    "        return (c,b,w)\n",
    "    \n",
    "    def gaussian_x(self, x: tc.Tensor):\n",
    "        \"\"\"        \n",
    "        Input :  a SCALAR x of shape (0,)\n",
    "        Output : a SCALAR\n",
    "        \"\"\"\n",
    "        c, b, w = self.splitter_gaussian()\n",
    "        return tc.sum(c*tc.exp(-w**2 *(x-b).T**2)) \n",
    "    \n",
    "    \"\"\" def forward_t(self, theta, x):\n",
    "        self.theta = theta\n",
    "        c,b,w = self.splitter_gaussian()\n",
    "        diff = x.unsqueeze(2)-b.t().unsqueeze(0) # tensor with shape (npoints,d,m)\n",
    "        distance = torch.norm(diff, dim=1)**2 # tensor of dimension (npoints, m)\n",
    "        exp_factor = torch.exp(-w.unsqueeze(0)**2*distance)\n",
    "        return torch.sum(c.unsqueeze(0)*exp_factor, dim=1).unsqueeze(1) \"\"\"\n",
    "    def forward_t(self, theta, x):\n",
    "        self.theta = theta\n",
    "        c,b,w = self.splitter_gaussian()\n",
    "        vect=lambda x: (c*tc.exp(-w**2*(x-b)**2)).sum()\n",
    "        return vect(x)\n",
    "    \n",
    "    def grad_theta(self, theta, samples):\n",
    "        self.theta = theta\n",
    "        jacobian = jacrev(lambda theta, x: self.forward_t(theta, x),  argnums=0)(theta, samples)\n",
    "        return jacobian.squeeze()\n",
    "    def out_prod(self,theta,x):\n",
    "        out_p=lambda theta,x_: tc.outer(self.grad_theta(theta,x_),self.grad_theta(theta,x_))\n",
    "        M=vmap((out_p),in_dims=(None,0))(theta,x)\n",
    "        return tc.mean(M,dim=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 15])\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "d = 1\n",
    "m = 5\n",
    "NN = Model(d,m)\n",
    "theta = NN.theta\n",
    "samples = torch.rand(2, d)\n",
    "#print(samples.T)\n",
    "#print(NN.forward(samples).T)\n",
    "\n",
    "#result_grad = NN.grad_theta(theta, samples[1])\n",
    "#end = time.time()\n",
    "#print(end-start)\n",
    "#print(NN.forward_t(theta,samples).unsqueeze())\n",
    "#print(result_grad.shape)\n",
    "MatrixM=NN.out_prod(theta,samples)\n",
    "print(MatrixM.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 30])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" tensorproduct = torch.zeros(samples.size()[0], NN.theta.size()[0], NN.theta.size()[0])\n",
    "for iter in range(0, samples.size()[0]):\n",
    "    tensorproduct[iter] = torch.outer(result_grad[iter], result_grad[iter]) \n",
    "    \n",
    "torch.mean(tensorproduct, dim=0).shape \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" def u(theta,x):\n",
    "    return x**2*theta.dot(theta)\n",
    "n=10\n",
    "space_x=tc.linspace(0,4,100)\n",
    "theta=tc.rand(n)\n",
    "def grad_u(theta,x):\n",
    "    return jacrev(u,argnums=0)(theta,x)\n",
    "def out_prod(theta,vect_x):\n",
    "    M=lambda vect,x: tc.outer(grad_u(vect,x),grad_u(vect,x))\n",
    "    return vmap((M),in_dims=(None,0))(theta,vect_x)\n",
    "    \n",
    "M=tc.mean(out_prod(theta,space_x),dim=0)\n",
    "print(M.shape) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m M\u001b[39m=\u001b[39mMatrixM(d, m, samples)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not callable"
     ]
    }
   ],
   "source": [
    "M=MatrixM(d, m, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inverse-neural-galerkin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
